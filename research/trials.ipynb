{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec324a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ff08e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\abhay\\\\Downloads'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "836717cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf4bccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (5.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (4.57.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee1ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa7906d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-groq in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.75 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-groq) (0.3.77)\n",
      "Requirement already satisfied: groq<1,>=0.30.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-groq) (0.32.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from groq<1,>=0.30.0->langchain-groq) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from groq<1,>=0.30.0->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from groq<1,>=0.30.0->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from groq<1,>=0.30.0->langchain-groq) (2.11.9)\n",
      "Requirement already satisfied: sniffio in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from groq<1,>=0.30.0->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from groq<1,>=0.30.0->langchain-groq) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.30.0->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.30.0->langchain-groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (0.16.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.4.31)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (6.0.3)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain-groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a665bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error loading file EAadhaar_2906003950031820200929114610_22092024222822.pdf\n"
     ]
    },
    {
     "ename": "FileNotDecryptedError",
     "evalue": "File has not been decrypted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotDecryptedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Load all PDFs from current directory (Data.pdf and Data2.pdf)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading PDF files...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_pdf_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(extracted_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m documents\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m text_chunks \u001b[38;5;241m=\u001b[39m text_split(extracted_data)\n",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m, in \u001b[0;36mload_pdf_file\u001b[1;34m(data_path)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load PDF files from specified directory\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m loader \u001b[38;5;241m=\u001b[39m DirectoryLoader(data_path, glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, loader_cls\u001b[38;5;241m=\u001b[39mPyPDFLoader)\n\u001b[1;32m---> 21\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m documents\n",
      "File \u001b[1;32mc:\\Users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:117\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:195\u001b[0m, in \u001b[0;36mDirectoryLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[1;32m--> 195\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_load_file(i, p, pbar)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pbar:\n\u001b[0;32m    198\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:233\u001b[0m, in \u001b[0;36mDirectoryLoader._lazy_load_file\u001b[1;34m(self, item, path, pbar)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(item)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 233\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pbar:\n",
      "File \u001b[1;32mc:\\Users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:223\u001b[0m, in \u001b[0;36mDirectoryLoader._lazy_load_file\u001b[1;34m(self, item, path, pbar)\u001b[0m\n\u001b[0;32m    221\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_cls(\u001b[38;5;28mstr\u001b[39m(item), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_kwargs)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 223\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdoc \u001b[38;5;129;01min\u001b[39;00m loader\u001b[38;5;241m.\u001b[39mlazy_load():\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m subdoc\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:305\u001b[0m, in \u001b[0;36mPyPDFLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    304\u001b[0m     blob \u001b[38;5;241m=\u001b[39m Blob\u001b[38;5;241m.\u001b[39mfrom_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)\n\u001b[1;32m--> 305\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mlazy_parse(blob)\n",
      "File \u001b[1;32mc:\\Users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:388\u001b[0m, in \u001b[0;36mPyPDFParser.lazy_parse\u001b[1;34m(self, blob)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m blob\u001b[38;5;241m.\u001b[39mas_bytes_io() \u001b[38;5;28;01mas\u001b[39;00m pdf_file_obj:\n\u001b[0;32m    384\u001b[0m     pdf_reader \u001b[38;5;241m=\u001b[39m pypdf\u001b[38;5;241m.\u001b[39mPdfReader(pdf_file_obj, password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpassword)\n\u001b[0;32m    386\u001b[0m     doc_metadata \u001b[38;5;241m=\u001b[39m _purge_metadata(\n\u001b[0;32m    387\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproducer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyPDF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreator\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyPDF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreationdate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m--> 388\u001b[0m         \u001b[38;5;241m|\u001b[39m cast(\u001b[38;5;28mdict\u001b[39m, \u001b[43mpdf_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;241m|\u001b[39m {\n\u001b[0;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: blob\u001b[38;5;241m.\u001b[39msource,\n\u001b[0;32m    391\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_pages\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mlen\u001b[39m(pdf_reader\u001b[38;5;241m.\u001b[39mpages),\n\u001b[0;32m    392\u001b[0m         }\n\u001b[0;32m    393\u001b[0m     )\n\u001b[0;32m    394\u001b[0m     single_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page_number, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pdf_reader\u001b[38;5;241m.\u001b[39mpages):\n",
      "File \u001b[1;32mc:\\Users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages\\pypdf\\_doc_common.py:308\u001b[0m, in \u001b[0;36mPdfDocCommon.metadata\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03mRetrieve the PDF file's document information dictionary, if it exists.\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03maccessed by this function.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    307\u001b[0m retval \u001b[38;5;241m=\u001b[39m DocumentInformation()\n\u001b[1;32m--> 308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    310\u001b[0m retval\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info)\n",
      "File \u001b[1;32mc:\\Users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages\\pypdf\\_reader.py:250\u001b[0m, in \u001b[0;36mPdfReader._info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03mProvide access to \"/Info\". Standardized with PdfWriter.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m \n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    249\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrailer\u001b[38;5;241m.\u001b[39mget(TK\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_null_or_none\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmypy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages\\pypdf\\generic\\_base.py:932\u001b[0m, in \u001b[0;36mis_null_or_none\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_null_or_none\u001b[39m(x: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TypeGuard[Union[\u001b[38;5;28;01mNone\u001b[39;00m, NullObject, IndirectObject]]:\n\u001b[0;32m    925\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;124;03m        True if x is None or NullObject.\u001b[39;00m\n\u001b[0;32m    928\u001b[0m \n\u001b[0;32m    929\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    931\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(x, PdfObject)\n\u001b[1;32m--> 932\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mget_object(), NullObject))\n\u001b[0;32m    933\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages\\pypdf\\generic\\_base.py:377\u001b[0m, in \u001b[0;36mIndirectObject.get_object\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_object\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPdfObject\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages\\pypdf\\_reader.py:470\u001b[0m, in \u001b[0;36mPdfReader.get_object\u001b[1;34m(self, indirect_reference)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_override_encryption \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encryption \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# if we don't have the encryption key:\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encryption\u001b[38;5;241m.\u001b[39mis_decrypted():\n\u001b[1;32m--> 470\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FileNotDecryptedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile has not been decrypted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;66;03m# otherwise, decrypt here...\u001b[39;00m\n\u001b[0;32m    472\u001b[0m     retval \u001b[38;5;241m=\u001b[39m cast(PdfObject, retval)\n",
      "\u001b[1;31mFileNotDecryptedError\u001b[0m: File has not been decrypted"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 0. Import necessary modules\n",
    "# -----------------------\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# -----------------------\n",
    "# 1. Load and Split PDF Data\n",
    "# -----------------------\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_pdf_file(data_path):\n",
    "    \"\"\"Load PDF files from specified directory\"\"\"\n",
    "    loader = DirectoryLoader(data_path, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "def text_split(extracted_data):\n",
    "    \"\"\"Split documents into chunks\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "# Load all PDFs from current directory (Data.pdf and Data2.pdf)\n",
    "print(\"Loading PDF files...\")\n",
    "extracted_data = load_pdf_file(data_path=\"./\")\n",
    "print(f\"Loaded {len(extracted_data)} documents\")\n",
    "\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Length of Text Chunks:\", len(text_chunks))\n",
    "\n",
    "# -----------------------\n",
    "# 2. Download HuggingFace Embeddings\n",
    "# -----------------------\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "def download_hugging_face_embeddings():\n",
    "    \"\"\"Initialize HuggingFace embeddings model\"\"\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings\n",
    "\n",
    "print(\"Loading embeddings model...\")\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Embedding vector length:\", len(query_result))\n",
    "\n",
    "# -----------------------\n",
    "# 3. Set up Pinecone\n",
    "# -----------------------\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import time\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"mkc\"\n",
    "\n",
    "# Delete existing index to start fresh with both books\n",
    "print(\"Checking for existing index...\")\n",
    "if index_name in [index.name for index in pc.list_indexes()]:\n",
    "    print(f\"Deleting existing index: {index_name}\")\n",
    "    pc.delete_index(index_name)\n",
    "    print(\"Waiting for deletion to complete...\")\n",
    "    time.sleep(5)  # Wait for deletion to complete\n",
    "\n",
    "# Create new index\n",
    "print(\"Creating new index...\")\n",
    "if index_name not in [index.name for index in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "    print(\"Waiting for index to be ready...\")\n",
    "    time.sleep(10)  # Wait for index to be ready\n",
    "\n",
    "# -----------------------\n",
    "# 4. Upload Embeddings to Pinecone\n",
    "# -----------------------\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "print(\"Uploading embeddings to Pinecone...\")\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "print(\"Upload complete!\")\n",
    "\n",
    "# -----------------------\n",
    "# 5. Set up Retriever\n",
    "# -----------------------\n",
    "print(\"Setting up retriever...\")\n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# Test retrieval\n",
    "print(\"\\nTesting retrieval...\")\n",
    "retrieved_docs = retriever.invoke(\"What is Acne?\")\n",
    "print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
    "\n",
    "# -----------------------\n",
    "# 6. Set up Groq LLM\n",
    "# -----------------------\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "print(\"Setting up LLM...\")\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=1024,\n",
    "    api_key=GROQ_API_KEY\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 7. Create RAG Chain\n",
    "# -----------------------\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "print(\"Creating RAG chain...\")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 8. Query the System\n",
    "# -----------------------\n",
    "def query_rag_system(question):\n",
    "    \"\"\"Query the RAG system with a question\"\"\"\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RAG System Ready!\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nTesting with sample question...\")\n",
    "result = query_rag_system(\"What is Acne?\")\n",
    "print(\"\\nQuestion: What is Acne?\")\n",
    "print(\"\\nAnswer:\", result['result'])\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"You can now query from both Data.pdf and Data2.pdf!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba877155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: It's possible that you're experiencing symptoms related to sleep apnea, which can cause fatigue, heart problems, and shortness of breath. The swelling in your ankles could be a sign of cardiovascular issues, such as high blood pressure or left ventricular failure, which can be associated with sleep apnea. I recommend consulting a doctor to determine the underlying cause of your symptoms and receive proper diagnosis and treatment.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0.4,\n",
    "    max_tokens=500,\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    api_key=GROQ_API_KEY\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 7. Create RAG Chain\n",
    "# -----------------------\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\\n\\n{context}\"\n",
    ")\n",
    "\n",
    "#done\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "# -----------------------\n",
    "# 8. Test the RAG System\n",
    "# -----------------------\n",
    "response = rag_chain.invoke({\"input\":\"Lately, I've been feeling extremely tired, even after a full night's sleep. I also noticed that my heart races sometimes and I get short of breath just from climbing a few stairs. I've had some swelling in my ankles too. I thought it was just stress, but it’s been going on for weeks now.\"})\n",
    "print(\"Response 1:\", response[\"answer\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b976e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: For asthma, treatments include bronchodilators to widen narrowed airways, and newer medications taken daily to prevent asthma attacks. To manage your condition, it's recommended to minimize exposure to allergens and avoid asthma and allergy triggers. Additionally, urgent measures to control asthma attacks and ongoing treatment to prevent attacks are equally important to prevent respiratory failure.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"I have asthma and sometimes struggle with shortness of breath. What treatments are recommended, and what precautions should I take to manage my condition\"})\n",
    "print(\"Response 1:\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa8bbf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: For a cold and body pain, you can try over-the-counter medications such as aspirin or nonsteroidal anti-inflammatory drugs (NSAIDs) like ibuprofen to relieve headache and muscle pain. Additionally, decongestants can help relieve stuffiness or a runny nose. However, it's always best to consult a doctor before taking any medication.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"i am suffering from coldaswell as high pain in body suggest me some   medicine \"})\n",
    "print(\"Response 1:\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ed37cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rag_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrag_chain\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m give me sybptom of maleria\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse 1:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rag_chain' is not defined"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \" give me sybptom of maleria\"})\n",
    "print(\"Response 1:\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eacec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ecb9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897ad2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da1116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
