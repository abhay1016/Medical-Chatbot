{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec324a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ff08e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\abhay\\\\Downloads\\\\Medical Chatbot'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836717cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf4bccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (5.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (4.57.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee1ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa7906d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-groq in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.75 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-groq) (0.3.77)\n",
      "Requirement already satisfied: groq<1,>=0.30.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-groq) (0.32.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from groq<1,>=0.30.0->langchain-groq) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from groq<1,>=0.30.0->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from groq<1,>=0.30.0->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from groq<1,>=0.30.0->langchain-groq) (2.11.9)\n",
      "Requirement already satisfied: sniffio in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from groq<1,>=0.30.0->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from groq<1,>=0.30.0->langchain-groq) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.30.0->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.30.0->langchain-groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (0.16.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.4.31)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (6.0.3)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.75->langchain-groq) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.30.0->langchain-groq) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhay\\.conda\\envs\\medibot\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.75->langchain-groq) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain-groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a665bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 4\n",
      "python-dotenv could not parse statement starting at line 6\n",
      "python-dotenv could not parse statement starting at line 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF files...\n",
      "Loaded 4843 documents\n",
      "Length of Text Chunks: 43035\n",
      "Loading embeddings model...\n",
      "Embedding vector length: 384\n",
      "Checking for existing index...\n",
      "Deleting existing index: mkc\n",
      "Waiting for deletion to complete...\n",
      "Creating new index...\n",
      "Waiting for index to be ready...\n",
      "Uploading embeddings to Pinecone...\n",
      "Upload complete!\n",
      "Setting up retriever...\n",
      "\n",
      "Testing retrieval...\n",
      "Retrieved 3 documents\n",
      "Setting up LLM...\n",
      "Creating RAG chain...\n",
      "\n",
      "==================================================\n",
      "RAG System Ready!\n",
      "==================================================\n",
      "\n",
      "Testing with sample question...\n",
      "\n",
      "Question: What is Acne?\n",
      "\n",
      "Answer: Acne is a skin disorder in which the sebaceous glands become inflamed, characterized by common blemishes such as blackheads, whiteheads, and yellowheads (pustules), often associated with high hormone levels, clogged pores, and increased production of sebum, the skin's oily secretion.\n",
      "\n",
      "==================================================\n",
      "You can now query from both Data.pdf and Data2.pdf!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 0. Import necessary modules\n",
    "# -----------------------\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# -----------------------\n",
    "# 1. Load and Split PDF Data\n",
    "# -----------------------\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_pdf_file(data_path):\n",
    "    \"\"\"Load PDF files from specified directory\"\"\"\n",
    "    loader = DirectoryLoader(data_path, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "def text_split(extracted_data):\n",
    "    \"\"\"Split documents into chunks\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "# Load all PDFs from current directory (Data.pdf and Data2.pdf)\n",
    "print(\"Loading PDF files...\")\n",
    "extracted_data = load_pdf_file(data_path=\"./\")\n",
    "print(f\"Loaded {len(extracted_data)} documents\")\n",
    "\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Length of Text Chunks:\", len(text_chunks))\n",
    "\n",
    "# -----------------------\n",
    "# 2. Download HuggingFace Embeddings\n",
    "# -----------------------\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "def download_hugging_face_embeddings():\n",
    "    \"\"\"Initialize HuggingFace embeddings model\"\"\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings\n",
    "\n",
    "print(\"Loading embeddings model...\")\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Embedding vector length:\", len(query_result))\n",
    "\n",
    "# -----------------------\n",
    "# 3. Set up Pinecone\n",
    "# -----------------------\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import time\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"mkc\"\n",
    "\n",
    "# Delete existing index to start fresh with both books\n",
    "print(\"Checking for existing index...\")\n",
    "if index_name in [index.name for index in pc.list_indexes()]:\n",
    "    print(f\"Deleting existing index: {index_name}\")\n",
    "    pc.delete_index(index_name)\n",
    "    print(\"Waiting for deletion to complete...\")\n",
    "    time.sleep(5)  # Wait for deletion to complete\n",
    "\n",
    "# Create new index\n",
    "print(\"Creating new index...\")\n",
    "if index_name not in [index.name for index in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "    print(\"Waiting for index to be ready...\")\n",
    "    time.sleep(10)  # Wait for index to be ready\n",
    "\n",
    "# -----------------------\n",
    "# 4. Upload Embeddings to Pinecone\n",
    "# -----------------------\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "print(\"Uploading embeddings to Pinecone...\")\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "print(\"Upload complete!\")\n",
    "\n",
    "# -----------------------\n",
    "# 5. Set up Retriever\n",
    "# -----------------------\n",
    "print(\"Setting up retriever...\")\n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# Test retrieval\n",
    "print(\"\\nTesting retrieval...\")\n",
    "retrieved_docs = retriever.invoke(\"What is Acne?\")\n",
    "print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
    "\n",
    "# -----------------------\n",
    "# 6. Set up Groq LLM\n",
    "# -----------------------\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "print(\"Setting up LLM...\")\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=1024,\n",
    "    api_key=GROQ_API_KEY\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 7. Create RAG Chain\n",
    "# -----------------------\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, \n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "print(\"Creating RAG chain...\")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 8. Query the System\n",
    "# -----------------------\n",
    "def query_rag_system(question):\n",
    "    \"\"\"Query the RAG system with a question\"\"\"\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RAG System Ready!\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nTesting with sample question...\")\n",
    "result = query_rag_system(\"What is Acne?\")\n",
    "print(\"\\nQuestion: What is Acne?\")\n",
    "print(\"\\nAnswer:\", result['result'])\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"You can now query from both Data.pdf and Data2.pdf!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba877155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: It's possible that you're experiencing symptoms related to sleep apnea, which can cause fatigue, heart problems, and shortness of breath. The swelling in your ankles could be a sign of cardiovascular issues, such as high blood pressure or left ventricular failure, which can be associated with sleep apnea. I recommend consulting a doctor to determine the underlying cause of your symptoms and receive proper diagnosis and treatment.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0.4,\n",
    "    max_tokens=500,\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    api_key=GROQ_API_KEY\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 7. Create RAG Chain\n",
    "# -----------------------\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\\n\\n{context}\"\n",
    ")\n",
    "\n",
    "#done\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "# -----------------------\n",
    "# 8. Test the RAG System\n",
    "# -----------------------\n",
    "response = rag_chain.invoke({\"input\":\"Lately, I've been feeling extremely tired, even after a full night's sleep. I also noticed that my heart races sometimes and I get short of breath just from climbing a few stairs. I've had some swelling in my ankles too. I thought it was just stress, but it’s been going on for weeks now.\"})\n",
    "print(\"Response 1:\", response[\"answer\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b976e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: For asthma, treatments include bronchodilators to widen narrowed airways, and newer medications taken daily to prevent asthma attacks. To manage your condition, it's recommended to minimize exposure to allergens and avoid asthma and allergy triggers. Additionally, urgent measures to control asthma attacks and ongoing treatment to prevent attacks are equally important to prevent respiratory failure.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"I have asthma and sometimes struggle with shortness of breath. What treatments are recommended, and what precautions should I take to manage my condition\"})\n",
    "print(\"Response 1:\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa8bbf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: For a cold and body pain, you can try over-the-counter medications such as aspirin or nonsteroidal anti-inflammatory drugs (NSAIDs) like ibuprofen to relieve headache and muscle pain. Additionally, decongestants can help relieve stuffiness or a runny nose. However, it's always best to consult a doctor before taking any medication.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"i am suffering from coldaswell as high pain in body suggest me some   medicine \"})\n",
    "print(\"Response 1:\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2ed37cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: I don't know the symptoms of malaria from the given context.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \" give me sybptom of maleria\"})\n",
    "print(\"Response 1:\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eacec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ecb9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897ad2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da1116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
